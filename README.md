# ðŸ“š Paper Reading Log

Automatically visualize your paper reading log below:

<!--CHART_START-->
![By category](assets/category_stylish.svg)

![Activity heatmap](assets/activity_heatmap.svg)


**Breakdown**

| Category | Count |
|---|---|
| LLM | 10 |
| TTS | 5 |
| Multimodal (T/S) | 3 |
| Dataset (Speech) | 1 |
| Speech | 1 |
| THG | 1 |
| **Total** | **21** |

**Recently read**

- [Predicting the Order of Upcoming Tokens Improves Language Modeling](https://arxiv.org/abs/2508.19228) â€” *LLM* (2025-08-29)
- [WavReward: Spoken Dialogue Models With Generalist Reward Evaluators](https://arxiv.org/abs/2505.09558) â€” *Multimodal (T/S)* (2025-08-28)
- [LIST: Language-Independent Speech Token for Multilingual Speech Synthesis with Language Models](https://www.isca-archive.org/interspeech_2025/liu25o_interspeech.pdf) â€” *TTS* (2025-08-28)
- [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611) â€” *Multimodal (T/S)* (2025-08-28)
- [Scalable Spontaneous Speech Dataset (SSSD): Crowdsourcing Data Collection to Promote Dialogue Research](https://www.isca-archive.org/interspeech_2025/sheikh25_interspeech.pdf) â€” *Dataset (Speech)* (2025-08-27)
- [CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training](https://arxiv.org/abs/2505.17589) â€” *TTS* (2025-05-28)
- [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/abs/2503.20783) â€” *LLM* (2025-05-27)
- [How Do Large Language Models Acquire Factual Knowledge During Pretraining?](https://arxiv.org/abs/2406.11813) â€” *LLM* (2025-05-16)
- [Qwen3: Think Deeper, Act Faster](https://qwenlm.github.io/blog/qwen3/) â€” *LLM* (2025-04-30)
- [ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning](https://arxiv.org/abs/2412.03104) â€” *LLM* (2025-04-28)
<!--CHART_END-->

## How to add a new paper

Add paper info to `data/papers.yml` in the following format:

```yaml
- title: "Your paper title"
  category: "LLM"
  date: "YYYY-MM-DD"
  link: "https://..."
```
